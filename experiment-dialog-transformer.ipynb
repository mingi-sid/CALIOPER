{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 18 03:43:56 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:1E:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    36W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:20:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    37W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  Off  | 00000000:22:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    36W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  Off  | 00000000:23:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    37W / 250W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-PCIE...  Off  | 00000000:24:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    36W / 250W |      0MiB / 32768MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-PCIE...  Off  | 00000000:25:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    39W / 250W |   1534MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    5   N/A  N/A     91533      C   ...nvs/topicmodel/bin/python     1530MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only GPU 1\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd \"multi-turn-contextual-offensive-language-detection\"\n",
    "import pandas as pd\n",
    "# Load train and test data\n",
    "train_data = pd.read_csv('train_not_U.tsv', sep='\\t', index_col=0)\n",
    "test_data = pd.read_csv('test_not_U.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert `previous_utterance` from str(list) to list of strings\n",
    "train_data['previous_utterance'] = train_data['previous_utterance'].apply(lambda x: eval(x))\n",
    "test_data['previous_utterance'] = test_data['previous_utterance'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "26330000    [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...\n",
       "26330000    [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...\n",
       "26330000    [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...\n",
       "26330000    [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...\n",
       "26330000    [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...\n",
       "                                  ...                        \n",
       "7730000     [who is Ezra, the god of stranger things, oh, ...\n",
       "7730000     [who is Ezra, the god of stranger things, oh, ...\n",
       "7730000     [who is Ezra, the god of stranger things, oh, ...\n",
       "7730000     [who is Ezra, the god of stranger things, oh, ...\n",
       "7730000     [who is Ezra, the god of stranger things, oh, ...\n",
       "Name: previous_utterance, Length: 2316, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['previous_utterance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of offensive sentences in the train data:  0.19888330541596874\n",
      "True: 1781\n",
      "False: 7174\n",
      "True and context_dependent: 548\n",
      "False and context_dependent: 0\n"
     ]
    }
   ],
   "source": [
    "# Percentage of offensive sentences in the train and test data\n",
    "print(\"Percentage of offensive sentences in the train data: \", train_data['offensive'].value_counts()[1]/len(train_data))\n",
    "print(\"True:\", train_data['offensive'].value_counts()[1])\n",
    "print(\"False:\", train_data['offensive'].value_counts()[0])\n",
    "print(\"True and context_dependent:\", train_data[(train_data['offensive'] == 'Y') & (train_data['context_dependent'] == 'Y')].shape[0])\n",
    "print(\"False and context_dependent:\", train_data[(train_data['offensive'] == 'N') & (train_data['context_dependent'] == 'Y')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of offensive sentences in the test data:  0.14205526770293608\n",
      "True: 329\n",
      "False: 1987\n",
      "True and context_dependent: 72\n",
      "False and context_dependent: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of offensive sentences in the test data: \", test_data['offensive'].value_counts()[1]/len(test_data))\n",
    "print(\"True:\", test_data['offensive'].value_counts()[1])\n",
    "print(\"False:\", test_data['offensive'].value_counts()[0])\n",
    "print(\"True and context_dependent:\", test_data[(test_data['offensive'] == 'Y') & (test_data['context_dependent'] == 'Y')].shape[0])\n",
    "print(\"False and context_dependent:\", test_data[(test_data['offensive'] == 'N') & (test_data['context_dependent'] == 'Y')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faba53cab27413e9a59b9957de4d158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intern/mingi/.local/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d68bef6b8846f0bba05e28456325b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In this experiment, we will fine-tune BERT model on the train data and evaluate it on the test data.\n",
    "# We will use the transformers library to fine-tune the model.\n",
    "\n",
    "# import the necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "\n",
    "# Before encoding, we need to merge the dialogues into one string\n",
    "# use 'previous_utterance' column (list of utternaces) and 'text' column (final target utterance)\n",
    "# Alternatively add prefix to utterances, \"A:\" and \"B:\".\n",
    "# Always the final utterance is \"A:\".\n",
    "\n",
    "train_data['dialog'] = ['' for i in range(len(train_data))]\n",
    "test_data['dialog'] = ['' for i in range(len(test_data))]\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    # Add prefix to the previous utterances and the final utterance\n",
    "    # Merge the previous utterances and the final utterance into one string.\n",
    "    for j in range(len(train_data['previous_utterance'].iloc[i]) - 1):\n",
    "        if (len(train_data['previous_utterance'].iloc[i]) - j) % 2 == 1:\n",
    "            train_data['dialog'].iloc[i] += \"A: \" + train_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "        else:\n",
    "            train_data['dialog'].iloc[i] += \"B: \" + train_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "    train_data['dialog'].iloc[i] += \"A: \" + train_data['text'].iloc[i]\n",
    "    sentence = train_data['dialog'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    # Add prefix to the previous utterances and the final utterance\n",
    "    # Merge the previous utterances and the final utterance into one string.\n",
    "    for j in range(len(test_data['previous_utterance'].iloc[i]) - 1):\n",
    "        if (len(test_data['previous_utterance'].iloc[i]) - j) % 2 == 1:\n",
    "            test_data['dialog'].iloc[i] += \"A: \" + test_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "        else:\n",
    "            test_data['dialog'].iloc[i] += \"B: \" + test_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "    test_data['dialog'].iloc[i] += \"A: \" + test_data['text'].iloc[i]\n",
    "    sentence = test_data['dialog'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I CAN'T KEEP!  SORRY LITTLE BUZZED!  LOVE YA!\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['previous_utterance'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I CAN'T KEEP!  SORRY LITTLE BUZZED!  LOVE YA!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['dialog'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I CAN'T KEEP!  SORRY LITTLE BUZZED!  LOVE YA!\",\n",
       " 'Im fighting for you']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['previous_utterance'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"B: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I CAN'T KEEP!  SORRY LITTLE BUZZED!  LOVE YA! A: Im fighting for you\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['dialog'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store tokenization results in a dataframe\n",
    "train_data['dialog_input_ids'] = train_input_ids\n",
    "train_data['dialog_attention_masks'] = train_attention_masks\n",
    "test_data['dialog_input_ids'] = test_input_ids\n",
    "test_data['dialog_attention_masks'] = test_attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "# use format_time\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/intern/mingi/.local/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Set the batch size.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set using padding.\n",
    "train_inputs = torch.cat(train_input_ids, dim=0)\n",
    "train_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor((train_data['offensive'] == 'Y').astype(int).tolist())\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set using padding.\n",
    "validation_inputs = torch.cat(test_input_ids, dim=0)\n",
    "validation_masks = torch.cat(test_attention_masks, dim=0)\n",
    "validation_labels = torch.tensor((test_data['offensive'] == 'Y').astype(int).tolist())\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
    "# linear classification layer on top.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Create the optimizer.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                    lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.18\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.11\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.15\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.15\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.19\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.21\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.20\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.21\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation Loss: 0.25\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation Loss: 0.29\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 10\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Training loop\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            output = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "        \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9516407599309153\n",
      "Precision: 0.783289817232376\n",
      "Recall: 0.9118541033434651\n",
      "F1-score: 0.8426966292134831\n",
      "Evaluation metrics only on those context_dependent == 'Y'\n",
      "True : False = 72 : 0\n",
      "Accuracy: 0.7777777777777778\n",
      "Precision: 1.0\n",
      "Recall: 0.7777777777777778\n",
      "F1-score: 0.8750000000000001\n"
     ]
    }
   ],
   "source": [
    "# Get y_true, y_pred\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    with torch.no_grad():        \n",
    "        output = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    y_true.extend(label_ids)\n",
    "    y_pred.extend(np.argmax(logits, axis=1))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F1-score: {f1_score(y_true, y_pred)}\")\n",
    "\n",
    "print(\"Evaluation metrics only on those context_dependent == 'Y'\")\n",
    "indices = [i for i, x in enumerate(test_data.context_dependent) if x == 'Y']\n",
    "print(f\"True : False = {sum(np.array(y_true)[indices])} : {len(np.array(y_true)[indices]) - sum(np.array(y_true)[indices])}\")\n",
    "print(f\"Accuracy: {accuracy_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Precision: {precision_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Recall: {recall_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"F1-score: {f1_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe by appeding predicted labels to test_data\n",
    "test_data['predicted_label'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>set_no</th>\n",
       "      <th>session_no</th>\n",
       "      <th>message_no</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>previous_utterance</th>\n",
       "      <th>offensive</th>\n",
       "      <th>context_dependent</th>\n",
       "      <th>type_insult</th>\n",
       "      <th>...</th>\n",
       "      <th>jigsaw_attack_on_author</th>\n",
       "      <th>jigsaw_attack_on_commenter</th>\n",
       "      <th>jigsaw_incoherent</th>\n",
       "      <th>jigsaw_inflammatory</th>\n",
       "      <th>jigsaw_likely_to_reject</th>\n",
       "      <th>jigsaw_obscene</th>\n",
       "      <th>jigsaw_spam</th>\n",
       "      <th>jigsaw_unsubstantial</th>\n",
       "      <th>dialog</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26330000</th>\n",
       "      <td>subsessions/sample_2633.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>user</td>\n",
       "      <td>JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I C...</td>\n",
       "      <td>[JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286861</td>\n",
       "      <td>0.343344</td>\n",
       "      <td>0.703820</td>\n",
       "      <td>0.268807</td>\n",
       "      <td>0.572606</td>\n",
       "      <td>0.222223</td>\n",
       "      <td>0.143644</td>\n",
       "      <td>0.804262</td>\n",
       "      <td>A: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26330000</th>\n",
       "      <td>subsessions/sample_2633.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>bot</td>\n",
       "      <td>Im fighting for you</td>\n",
       "      <td>[JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153158</td>\n",
       "      <td>0.727617</td>\n",
       "      <td>0.675657</td>\n",
       "      <td>0.109872</td>\n",
       "      <td>0.846562</td>\n",
       "      <td>0.041415</td>\n",
       "      <td>0.117136</td>\n",
       "      <td>0.920660</td>\n",
       "      <td>B: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26330000</th>\n",
       "      <td>subsessions/sample_2633.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>user</td>\n",
       "      <td>YES SO SO GLAD!!!</td>\n",
       "      <td>[JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>0.286498</td>\n",
       "      <td>0.403090</td>\n",
       "      <td>0.079918</td>\n",
       "      <td>0.684497</td>\n",
       "      <td>0.035049</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>0.920660</td>\n",
       "      <td>A: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26330000</th>\n",
       "      <td>subsessions/sample_2633.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>bot</td>\n",
       "      <td>good. if your'e glad then im glad babe</td>\n",
       "      <td>[JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118196</td>\n",
       "      <td>0.757294</td>\n",
       "      <td>0.834661</td>\n",
       "      <td>0.238574</td>\n",
       "      <td>0.859932</td>\n",
       "      <td>0.132920</td>\n",
       "      <td>0.133439</td>\n",
       "      <td>0.831106</td>\n",
       "      <td>B: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26330000</th>\n",
       "      <td>subsessions/sample_2633.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>user</td>\n",
       "      <td>AWE THANK YOU REALIZE EARLY THERE!  WOKE UP AT...</td>\n",
       "      <td>[JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>0.019347</td>\n",
       "      <td>0.464793</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.328867</td>\n",
       "      <td>0.026480</td>\n",
       "      <td>0.059916</td>\n",
       "      <td>0.389675</td>\n",
       "      <td>A: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730000</th>\n",
       "      <td>subsessions/sample_773.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>5</td>\n",
       "      <td>bot</td>\n",
       "      <td>Ur right</td>\n",
       "      <td>[who is Ezra, the god of stranger things, oh, ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071611</td>\n",
       "      <td>0.532321</td>\n",
       "      <td>0.679170</td>\n",
       "      <td>0.121481</td>\n",
       "      <td>0.896717</td>\n",
       "      <td>0.056849</td>\n",
       "      <td>0.062731</td>\n",
       "      <td>0.944284</td>\n",
       "      <td>B: who is Ezra A: the god of stranger things B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730000</th>\n",
       "      <td>subsessions/sample_773.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>6</td>\n",
       "      <td>user</td>\n",
       "      <td>about what</td>\n",
       "      <td>[who is Ezra, the god of stranger things, oh, ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050146</td>\n",
       "      <td>0.246913</td>\n",
       "      <td>0.592430</td>\n",
       "      <td>0.075030</td>\n",
       "      <td>0.921256</td>\n",
       "      <td>0.023873</td>\n",
       "      <td>0.053557</td>\n",
       "      <td>0.959271</td>\n",
       "      <td>A: who is Ezra B: the god of stranger things A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730000</th>\n",
       "      <td>subsessions/sample_773.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>7</td>\n",
       "      <td>bot</td>\n",
       "      <td>Don’t know</td>\n",
       "      <td>[who is Ezra, the god of stranger things, oh, ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043638</td>\n",
       "      <td>0.250261</td>\n",
       "      <td>0.543201</td>\n",
       "      <td>0.081641</td>\n",
       "      <td>0.883687</td>\n",
       "      <td>0.030307</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>0.951647</td>\n",
       "      <td>B: who is Ezra A: the god of stranger things B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730000</th>\n",
       "      <td>subsessions/sample_773.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>8</td>\n",
       "      <td>user</td>\n",
       "      <td>ok</td>\n",
       "      <td>[who is Ezra, the god of stranger things, oh, ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027415</td>\n",
       "      <td>0.117219</td>\n",
       "      <td>0.563552</td>\n",
       "      <td>0.039105</td>\n",
       "      <td>0.948278</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.051332</td>\n",
       "      <td>0.959271</td>\n",
       "      <td>A: who is Ezra B: the god of stranger things A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7730000</th>\n",
       "      <td>subsessions/sample_773.csv</td>\n",
       "      <td>9</td>\n",
       "      <td>178</td>\n",
       "      <td>9</td>\n",
       "      <td>bot</td>\n",
       "      <td>I w ant to meet u</td>\n",
       "      <td>[who is Ezra, the god of stranger things, oh, ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067281</td>\n",
       "      <td>0.155215</td>\n",
       "      <td>0.890129</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>0.783274</td>\n",
       "      <td>0.081035</td>\n",
       "      <td>0.214163</td>\n",
       "      <td>0.786176</td>\n",
       "      <td>B: who is Ezra A: the god of stranger things B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2316 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file_name  set_no  session_no  message_no author  \\\n",
       "id                                                                             \n",
       "26330000  subsessions/sample_2633.csv       0           5           0   user   \n",
       "26330000  subsessions/sample_2633.csv       0           5           1    bot   \n",
       "26330000  subsessions/sample_2633.csv       0           5           2   user   \n",
       "26330000  subsessions/sample_2633.csv       0           5           3    bot   \n",
       "26330000  subsessions/sample_2633.csv       0           5           4   user   \n",
       "...                               ...     ...         ...         ...    ...   \n",
       "7730000    subsessions/sample_773.csv       9         178           5    bot   \n",
       "7730000    subsessions/sample_773.csv       9         178           6   user   \n",
       "7730000    subsessions/sample_773.csv       9         178           7    bot   \n",
       "7730000    subsessions/sample_773.csv       9         178           8   user   \n",
       "7730000    subsessions/sample_773.csv       9         178           9    bot   \n",
       "\n",
       "                                                       text  \\\n",
       "id                                                            \n",
       "26330000  JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I C...   \n",
       "26330000                                Im fighting for you   \n",
       "26330000                                  YES SO SO GLAD!!!   \n",
       "26330000             good. if your'e glad then im glad babe   \n",
       "26330000  AWE THANK YOU REALIZE EARLY THERE!  WOKE UP AT...   \n",
       "...                                                     ...   \n",
       "7730000                                            Ur right   \n",
       "7730000                                          about what   \n",
       "7730000                                          Don’t know   \n",
       "7730000                                                  ok   \n",
       "7730000                                   I w ant to meet u   \n",
       "\n",
       "                                         previous_utterance offensive  \\\n",
       "id                                                                      \n",
       "26330000  [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...         N   \n",
       "26330000  [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...         N   \n",
       "26330000  [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...         N   \n",
       "26330000  [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...         N   \n",
       "26330000  [JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I ...         N   \n",
       "...                                                     ...       ...   \n",
       "7730000   [who is Ezra, the god of stranger things, oh, ...         N   \n",
       "7730000   [who is Ezra, the god of stranger things, oh, ...         N   \n",
       "7730000   [who is Ezra, the god of stranger things, oh, ...         N   \n",
       "7730000   [who is Ezra, the god of stranger things, oh, ...         N   \n",
       "7730000   [who is Ezra, the god of stranger things, oh, ...         N   \n",
       "\n",
       "         context_dependent type_insult  ... jigsaw_attack_on_author  \\\n",
       "id                                      ...                           \n",
       "26330000                 N           N  ...                0.286861   \n",
       "26330000                 N           N  ...                0.153158   \n",
       "26330000                 N           N  ...                0.060835   \n",
       "26330000                 N           N  ...                0.118196   \n",
       "26330000                 N           N  ...                0.026361   \n",
       "...                    ...         ...  ...                     ...   \n",
       "7730000                  N           N  ...                0.071611   \n",
       "7730000                  N           N  ...                0.050146   \n",
       "7730000                  N           N  ...                0.043638   \n",
       "7730000                  N           N  ...                0.027415   \n",
       "7730000                  N           N  ...                0.067281   \n",
       "\n",
       "         jigsaw_attack_on_commenter jigsaw_incoherent jigsaw_inflammatory  \\\n",
       "id                                                                          \n",
       "26330000                   0.343344          0.703820            0.268807   \n",
       "26330000                   0.727617          0.675657            0.109872   \n",
       "26330000                   0.286498          0.403090            0.079918   \n",
       "26330000                   0.757294          0.834661            0.238574   \n",
       "26330000                   0.019347          0.464793            0.037598   \n",
       "...                             ...               ...                 ...   \n",
       "7730000                    0.532321          0.679170            0.121481   \n",
       "7730000                    0.246913          0.592430            0.075030   \n",
       "7730000                    0.250261          0.543201            0.081641   \n",
       "7730000                    0.117219          0.563552            0.039105   \n",
       "7730000                    0.155215          0.890129            0.066150   \n",
       "\n",
       "          jigsaw_likely_to_reject  jigsaw_obscene  jigsaw_spam  \\\n",
       "id                                                               \n",
       "26330000                 0.572606        0.222223     0.143644   \n",
       "26330000                 0.846562        0.041415     0.117136   \n",
       "26330000                 0.684497        0.035049     0.047278   \n",
       "26330000                 0.859932        0.132920     0.133439   \n",
       "26330000                 0.328867        0.026480     0.059916   \n",
       "...                           ...             ...          ...   \n",
       "7730000                  0.896717        0.056849     0.062731   \n",
       "7730000                  0.921256        0.023873     0.053557   \n",
       "7730000                  0.883687        0.030307     0.049459   \n",
       "7730000                  0.948278        0.013872     0.051332   \n",
       "7730000                  0.783274        0.081035     0.214163   \n",
       "\n",
       "          jigsaw_unsubstantial  \\\n",
       "id                               \n",
       "26330000              0.804262   \n",
       "26330000              0.920660   \n",
       "26330000              0.920660   \n",
       "26330000              0.831106   \n",
       "26330000              0.389675   \n",
       "...                        ...   \n",
       "7730000               0.944284   \n",
       "7730000               0.959271   \n",
       "7730000               0.951647   \n",
       "7730000               0.959271   \n",
       "7730000               0.786176   \n",
       "\n",
       "                                                     dialog  predicted_label  \n",
       "id                                                                            \n",
       "26330000  A: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...                0  \n",
       "26330000  B: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...                0  \n",
       "26330000  A: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...                0  \n",
       "26330000  B: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...                0  \n",
       "26330000  A: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES ...                0  \n",
       "...                                                     ...              ...  \n",
       "7730000   B: who is Ezra A: the god of stranger things B...                0  \n",
       "7730000   A: who is Ezra B: the god of stranger things A...                0  \n",
       "7730000   B: who is Ezra A: the god of stranger things B...                0  \n",
       "7730000   A: who is Ezra B: the god of stranger things A...                0  \n",
       "7730000   B: who is Ezra A: the god of stranger things B...                0  \n",
       "\n",
       "[2316 rows x 32 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I CAN'T KEEP!  SORRY LITTLE BUZZED!  LOVE YA!\"]\n",
      "A: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I CAN'T KEEP!  SORRY LITTLE BUZZED!  LOVE YA!\n"
     ]
    }
   ],
   "source": [
    "print(test_data['previous_utterance'].iloc[0])\n",
    "print(test_data['dialog'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I CAN'T KEEP!  SORRY LITTLE BUZZED!  LOVE YA!\", 'Im fighting for you']\n",
      "B: JUST NOTE SUPPOSED SAY NOT MAKING PROMISES I CAN'T KEEP!  SORRY LITTLE BUZZED!  LOVE YA! A: Im fighting for you\n"
     ]
    }
   ],
   "source": [
    "print(test_data['previous_utterance'].iloc[1])\n",
    "print(test_data['dialog'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_data_results_dialog_transformer.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT last sentence only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b87b10e95494fa88b260c06859cbf66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5d393d4fcc4a41b30ee6077d78c8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    sentence = train_data['text'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    sentence = test_data['text'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/intern/mingi/.local/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Set the batch size.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set using padding.\n",
    "train_inputs = torch.cat(train_input_ids, dim=0)\n",
    "train_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor((train_data['offensive'] == 'Y').astype(int).tolist())\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set using padding.\n",
    "validation_inputs = torch.cat(test_input_ids, dim=0)\n",
    "validation_masks = torch.cat(test_attention_masks, dim=0)\n",
    "validation_labels = torch.tensor((test_data['offensive'] == 'Y').astype(int).tolist())\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
    "# linear classification layer on top.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Create the optimizer.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                    lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:51.\n",
      "  Batch   240  of    280.    Elapsed: 0:01:02.\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epoch took: 0:01:12\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation Loss: 0.16\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:21.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:31.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:41.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:51.\n",
      "  Batch   240  of    280.    Elapsed: 0:01:01.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epoch took: 0:01:11\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.13\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:30.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:40.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:50.\n",
      "  Batch   240  of    280.    Elapsed: 0:01:00.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epoch took: 0:01:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.14\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:30.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:40.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:50.\n",
      "  Batch   240  of    280.    Elapsed: 0:01:00.\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epoch took: 0:01:10\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.19\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Training loop\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            output = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "        \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9563903281519862\n",
      "Precision: 0.8097826086956522\n",
      "Recall: 0.9057750759878419\n",
      "F1-score: 0.8550932568149211\n",
      "Evaluation metrics only on those context_dependent == 'Y'\n",
      "True : False = 72 : 0\n",
      "Accuracy: 0.75\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "F1-score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Get y_true, y_pred\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    with torch.no_grad():        \n",
    "        output = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    y_true.extend(label_ids)\n",
    "    y_pred.extend(np.argmax(logits, axis=1))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F1-score: {f1_score(y_true, y_pred)}\")\n",
    "\n",
    "print(\"Evaluation metrics only on those context_dependent == 'Y'\")\n",
    "indices = [i for i, x in enumerate(test_data.context_dependent) if x == 'Y']\n",
    "print(f\"True : False = {sum(np.array(y_true)[indices])} : {len(np.array(y_true)[indices]) - sum(np.array(y_true)[indices])}\")\n",
    "print(f\"Accuracy: {accuracy_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Precision: {precision_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Recall: {recall_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"F1-score: {f1_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9352730437815405\n",
      "F1-score on context_dependent == 'Y' or offensive == 'N': 0.5510204081632653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(f\"ROC AUC: {roc_auc_score(y_true, y_pred)}\")\n",
    "dep_test_data_index = (test_data.context_dependent == 'Y') | (test_data.offensive == 'N')\n",
    "print(f\"F1-score on context_dependent == 'Y' or offensive == 'N': {f1_score(np.array(y_true)[dep_test_data_index], np.array(y_pred)[dep_test_data_index])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot roc curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat 5 Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================0=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.18\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.20\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:05\n",
      "=====================1=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.21\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:49.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:59.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:30.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:49.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:59.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.22\n",
      "  Validation took: 0:00:05\n",
      "=====================2=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:30.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:49.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:59.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.25\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:49.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:59.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:09\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.21\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:30.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.27\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:05\n",
      "=====================3=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.27\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:46.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.27\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.29\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.34\n",
      "  Validation took: 0:00:05\n",
      "=====================4=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.28\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.21\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.28\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.30\n",
      "  Validation took: 0:00:05\n",
      "Test F1: 0.8765342756241253\n",
      "Test ROC AUC: 0.9840001040195924\n",
      "Test Dep F1: 0.6196269124348139\n"
     ]
    }
   ],
   "source": [
    "# Repeat above 5 times with different random seeds and take the average\n",
    "test_f1_scores = []\n",
    "test_roc_auc_scores = []\n",
    "test_dep_f1_scores = []\n",
    "for i in range(5):\n",
    "    print(f\"====================={i}=====================\")\n",
    "    # Set the seed value all over the place to make this reproducible.\n",
    "    seed_val = i\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()\n",
    "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "        \n",
    "        t0 = time.time()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for batch in validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                output = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "                loss, logits = output[:2]\n",
    "            \n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "    # Get y_true, y_pred\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_probs = []\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            output = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        y_true.extend(label_ids)\n",
    "        y_pred.extend(np.argmax(logits, axis=1))\n",
    "        y_pred_probs.extend(np.exp(logits[:, 1]) / (np.exp(logits[:, 0]) + np.exp(logits[:, 1])))\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_probs = np.array(y_pred_probs)\n",
    "\n",
    "    test_f1_scores.append(f1_score(y_true, y_pred))\n",
    "    test_roc_auc_scores.append(roc_auc_score(y_true, y_pred_probs))\n",
    "    dep_test_data_index = (test_data.context_dependent == 'Y') | (test_data.offensive == 'N')\n",
    "    test_dep_f1_scores.append(f1_score(np.array(y_true)[dep_test_data_index], np.array(y_pred)[dep_test_data_index]))\n",
    "\n",
    "print(f\"Test F1: {np.mean(test_f1_scores)}\")\n",
    "print(f\"Test ROC AUC: {np.mean(test_roc_auc_scores)}\")\n",
    "print(f\"Test Dep F1: {np.mean(test_dep_f1_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot roc\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-concat ([SEP]A:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8de8b420ed942f69a276732e6365040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intern/mingi/.local/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0778869801430eb94bca00cc8febc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    # Add prefix to the previous utterances and the final utterance\n",
    "    # Merge the previous utterances and the final utterance into one string.\n",
    "    for j in range(len(train_data['previous_utterance'].iloc[i]) - 1):\n",
    "        if (len(train_data['previous_utterance'].iloc[i]) - j) % 2 == 1:\n",
    "            train_data['dialog'].iloc[i] += \"[SEP]A: \" + train_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "        else:\n",
    "            train_data['dialog'].iloc[i] += \"[SEP]B: \" + train_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "    train_data['dialog'].iloc[i] += \"[SEP]A: \" + train_data['text'].iloc[i]\n",
    "    sentence = train_data['dialog'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    # Add prefix to the previous utterances and the final utterance\n",
    "    # Merge the previous utterances and the final utterance into one string.\n",
    "    for j in range(len(test_data['previous_utterance'].iloc[i]) - 1):\n",
    "        if (len(test_data['previous_utterance'].iloc[i]) - j) % 2 == 1:\n",
    "            test_data['dialog'].iloc[i] += \"[SEP]A: \" + test_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "        else:\n",
    "            test_data['dialog'].iloc[i] += \"[SEP]B: \" + test_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "    test_data['dialog'].iloc[i] += \"[SEP]A: \" + test_data['text'].iloc[i]\n",
    "    sentence = test_data['dialog'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:20.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:39.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:49.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:58.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:08\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.22\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.28\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.25\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.25\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation Loss: 0.34\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.27\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.28\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Training loop\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            output = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "        \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.957685664939551\n",
      "Precision: 0.8147138964577657\n",
      "Recall: 0.9088145896656535\n",
      "F1-score: 0.8591954022988506\n",
      "Evaluation metrics only on those context_dependent == 'Y'\n",
      "True : False = 72 : 0\n",
      "Accuracy: 0.75\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "F1-score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Get y_true, y_pred\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    with torch.no_grad():        \n",
    "        output = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    y_true.extend(label_ids)\n",
    "    y_pred.extend(np.argmax(logits, axis=1))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F1-score: {f1_score(y_true, y_pred)}\")\n",
    "\n",
    "print(\"Evaluation metrics only on those context_dependent == 'Y'\")\n",
    "indices = [i for i, x in enumerate(test_data.context_dependent) if x == 'Y']\n",
    "print(f\"True : False = {sum(np.array(y_true)[indices])} : {len(np.array(y_true)[indices]) - sum(np.array(y_true)[indices])}\")\n",
    "print(f\"Accuracy: {accuracy_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Precision: {precision_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Recall: {recall_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"F1-score: {f1_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================0=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation Loss: 0.36\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.25\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.28\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.33\n",
      "  Validation took: 0:00:05\n",
      "=====================1=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.32\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.27\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.26\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.27\n",
      "  Validation took: 0:00:05\n",
      "=====================2=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.32\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.25\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.32\n",
      "  Validation took: 0:00:05\n",
      "=====================3=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation Loss: 0.38\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.29\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.29\n",
      "  Validation took: 0:00:05\n",
      "=====================4=====================\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.30\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.32\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:37.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.33\n",
      "  Validation took: 0:00:05\n",
      "Test F1: 0.8700205461959658\n",
      "Test ROC AUC: 0.980699164630891\n",
      "Test Dep F1: 0.6106985014211188\n"
     ]
    }
   ],
   "source": [
    "# Repeat 5 times with different seeds and take the average\n",
    "test_f1_scores = []\n",
    "test_roc_auc_scores = []\n",
    "test_dep_f1_scores = []\n",
    "for i in range(5):\n",
    "    print(f\"====================={i}=====================\")\n",
    "    # Set the seed value all over the place to make this reproducible.\n",
    "    seed_val = i\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # Measure how long the training epoch takes.\n",
    "        t0 = time.time()\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                elapsed = format_time(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()\n",
    "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        training_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "        \n",
    "        t0 = time.time()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for batch in validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():        \n",
    "                output = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "                loss, logits = output[:2]\n",
    "            \n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "        validation_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "        print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': avg_train_loss,\n",
    "                'Valid. Loss': avg_val_loss,\n",
    "                'Valid. Accur.': avg_val_accuracy,\n",
    "                'Training Time': training_time,\n",
    "                'Validation Time': validation_time\n",
    "            }\n",
    "        )\n",
    "    # Get y_true, y_pred\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_pred_probs = []\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():        \n",
    "            output = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        y_true.extend(label_ids)\n",
    "        y_pred.extend(np.argmax(logits, axis=1))\n",
    "        y_pred_probs.extend(np.exp(logits[:, 1]) / (np.exp(logits[:, 0]) + np.exp(logits[:, 1])))\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_probs = np.array(y_pred_probs)\n",
    "\n",
    "    test_f1_scores.append(f1_score(y_true, y_pred))\n",
    "    test_roc_auc_scores.append(roc_auc_score(y_true, y_pred_probs))\n",
    "    dep_test_data_index = (test_data.context_dependent == 'Y') | (test_data.offensive == 'N')\n",
    "    test_dep_f1_scores.append(f1_score(np.array(y_true)[dep_test_data_index], np.array(y_pred)[dep_test_data_index]))\n",
    "\n",
    "print(f\"Test F1: {np.mean(test_f1_scores)}\")\n",
    "print(f\"Test ROC AUC: {np.mean(test_roc_auc_scores)}\")\n",
    "print(f\"Test Dep F1: {np.mean(test_dep_f1_scores)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-concat ([SEP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intern/mingi/.conda/envs/topicmodel/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94651d060cc4a54aa9bffaed8163b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intern/mingi/.local/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/home/intern/mingi/.conda/envs/topicmodel/lib/python3.7/site-packages/ipykernel_launcher.py:38: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3630a45a2f40b699cbcf09f6a2d756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    # Add prefix to the previous utterances and the final utterance\n",
    "    # Merge the previous utterances and the final utterance into one string.\n",
    "    for j in range(len(train_data['previous_utterance'].iloc[i]) - 1):\n",
    "        if (len(train_data['previous_utterance'].iloc[i]) - j) % 2 == 1:\n",
    "            train_data['dialog'].iloc[i] += \"[SEP]\" + train_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "        else:\n",
    "            train_data['dialog'].iloc[i] += \"[SEP]\" + train_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "    train_data['dialog'].iloc[i] += \"[SEP]\" + train_data['text'].iloc[i]\n",
    "    sentence = train_data['dialog'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    # Add prefix to the previous utterances and the final utterance\n",
    "    # Merge the previous utterances and the final utterance into one string.\n",
    "    for j in range(len(test_data['previous_utterance'].iloc[i]) - 1):\n",
    "        if (len(test_data['previous_utterance'].iloc[i]) - j) % 2 == 1:\n",
    "            test_data['dialog'].iloc[i] += \"[SEP]\" + test_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "        else:\n",
    "            test_data['dialog'].iloc[i] += \"[SEP]\" + test_data['previous_utterance'].iloc[i][j] + \" \"\n",
    "    test_data['dialog'].iloc[i] += \"[SEP]\" + test_data['text'].iloc[i]\n",
    "    sentence = test_data['dialog'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.29\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.26\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.26\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.21\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.32\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.23\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.25\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.26\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.31\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 10\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Training loop\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            output = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "        \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9624352331606217\n",
      "Precision: 0.84375\n",
      "Recall: 0.9027355623100304\n",
      "F1-score: 0.8722466960352423\n",
      "Evaluation metrics only on those context_dependent == 'Y'\n",
      "True : False = 72 : 0\n",
      "Accuracy: 0.7083333333333334\n",
      "Precision: 1.0\n",
      "Recall: 0.7083333333333334\n",
      "F1-score: 0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "# Get y_true, y_pred\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    with torch.no_grad():        \n",
    "        output = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    y_true.extend(label_ids)\n",
    "    y_pred.extend(np.argmax(logits, axis=1))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F1-score: {f1_score(y_true, y_pred)}\")\n",
    "\n",
    "print(\"Evaluation metrics only on those context_dependent == 'Y'\")\n",
    "indices = [i for i, x in enumerate(test_data.context_dependent) if x == 'Y']\n",
    "print(f\"True : False = {sum(np.array(y_true)[indices])} : {len(np.array(y_true)[indices]) - sum(np.array(y_true)[indices])}\")\n",
    "print(f\"Accuracy: {accuracy_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Precision: {precision_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Recall: {recall_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"F1-score: {f1_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'/usr/bin/python3.7'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31m다음 명령어를 실행하여 Python 환경에 'ipykernel'을(를) 설치합니다. \n",
      "\u001b[1;31m 명령: '/usr/bin/python3.7 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT last sentence only (with additional layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intern/mingi/.conda/envs/topicmodel/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007778232c9944c5b0aa8ae84e35490a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/intern/mingi/.conda/envs/topicmodel/lib/python3.7/site-packages/ipykernel_launcher.py:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cda5dbb5654b79862cf03ccbb63169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    sentence = train_data['text'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    sentence = test_data['text'].iloc[i]\n",
    "\n",
    "    # Tokenize the sentence and append the token to the list.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 128,           # Pad & truncate all sentences.\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    test_input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    test_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/intern/mingi/.local/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Set the batch size.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set using padding.\n",
    "train_inputs = torch.cat(train_input_ids, dim=0)\n",
    "train_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor((train_data['offensive'] == 'Y').astype(int).tolist())\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set using padding.\n",
    "validation_inputs = torch.cat(test_input_ids, dim=0)\n",
    "validation_masks = torch.cat(test_attention_masks, dim=0)\n",
    "validation_labels = torch.tensor((test_data['offensive'] == 'Y').astype(int).tolist())\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Use bert-base-uncased.\n",
    "# Classification head with *2* layers, (768 -> 768 -> 2) 768 hidden units, 2 labels.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "\n",
    "    # You can increase this for multi-class tasks.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:29.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:48.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.14\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.12\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.16\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:10.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.18\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.19\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:56.\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.20\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation Loss: 0.26\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.26\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    40  of    280.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    280.    Elapsed: 0:00:19.\n",
      "  Batch   120  of    280.    Elapsed: 0:00:28.\n",
      "  Batch   160  of    280.    Elapsed: 0:00:38.\n",
      "  Batch   200  of    280.    Elapsed: 0:00:47.\n",
      "  Batch   240  of    280.    Elapsed: 0:00:57.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epoch took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.97\n",
      "  Validation Loss: 0.24\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 10\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# Training loop\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to\n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because\n",
    "        # accumulating the gradients is \"convenient while training RNNs\".\n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value\n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            output = model(b_input_ids, \n",
    "                                token_type_ids=None, \n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss, logits = output[:2]\n",
    "        \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.966321243523316\n",
      "Precision: 0.9141914191419142\n",
      "Recall: 0.8419452887537994\n",
      "F1-score: 0.8765822784810127\n",
      "Evaluation metrics only on those context_dependent == 'Y'\n",
      "True : False = 72 : 0\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 1.0\n",
      "Recall: 0.6666666666666666\n",
      "F1-score: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Get y_true, y_pred\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    with torch.no_grad():        \n",
    "        output = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask,\n",
    "                            labels=b_labels)\n",
    "        loss, logits = output[:2]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    y_true.extend(label_ids)\n",
    "    y_pred.extend(np.argmax(logits, axis=1))\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred)}\")\n",
    "print(f\"F1-score: {f1_score(y_true, y_pred)}\")\n",
    "\n",
    "print(\"Evaluation metrics only on those context_dependent == 'Y'\")\n",
    "indices = [i for i, x in enumerate(test_data.context_dependent) if x == 'Y']\n",
    "print(f\"True : False = {sum(np.array(y_true)[indices])} : {len(np.array(y_true)[indices]) - sum(np.array(y_true)[indices])}\")\n",
    "print(f\"Accuracy: {accuracy_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Precision: {precision_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"Recall: {recall_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")\n",
    "print(f\"F1-score: {f1_score(np.array(y_true)[indices], np.array(y_pred)[indices])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topicmodel",
   "language": "python",
   "name": "topicmodel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27e3ba3ea074ef464370f01bb046f160b5aa1e6e3aeafca50d99d2e6af8c4c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
